{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pdfplumber\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def split_and_rename_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Splits a PDF into test and answer sections at the 'Answer Section'.\n",
    "    After splitting, the original file is renamed with a prefix '_'.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): The full path to the original PDF file.\n",
    "    \"\"\"\n",
    "    # Using pdfplumber to find the correct split index\n",
    "    split_index = None\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            if \"Answer Section\" in text:\n",
    "                split_index = i\n",
    "                break\n",
    "    \n",
    "    if split_index is None:\n",
    "        raise ValueError(\"The 'Answer Section' marker could not be found in the document.\")\n",
    "    \n",
    "    # Load the PDF file with PyPDF2 for splitting\n",
    "    reader = PdfReader(file_path)\n",
    "    \n",
    "    # Setup paths for the new PDF files\n",
    "    directory = os.path.dirname(file_path)\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    test_pdf_path = os.path.join(directory, f\"{base_name}_test.pdf\")\n",
    "    answer_pdf_path = os.path.join(directory, f\"{base_name}_answ.pdf\")\n",
    "    \n",
    "    # Initialize PDF writers for the two sections\n",
    "    test_writer = PdfWriter()\n",
    "    answer_writer = PdfWriter()\n",
    "    \n",
    "    # Split the pages based on the determined index\n",
    "    for i in range(len(reader.pages)):\n",
    "        if i < split_index:\n",
    "            test_writer.add_page(reader.pages[i])\n",
    "        else:\n",
    "            answer_writer.add_page(reader.pages[i])\n",
    "    \n",
    "    # Save the split PDFs to files\n",
    "    with open(test_pdf_path, \"wb\") as f:\n",
    "        test_writer.write(f)\n",
    "    with open(answer_pdf_path, \"wb\") as f:\n",
    "        answer_writer.write(f)\n",
    "    \n",
    "    # Rename the original file\n",
    "    new_file_path = os.path.join(directory, f\"_{base_name}.pdf\")\n",
    "    os.rename(file_path, new_file_path)\n",
    "    \n",
    "    print(f\"Test section saved to: {test_pdf_path}\")\n",
    "    print(f\"Answer section saved to: {answer_pdf_path}\")\n",
    "    print(f\"Original file renamed to: {new_file_path}\")\n",
    "    return test_pdf_path, answer_pdf_path, new_file_path\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Processes all PDF files in a given directory to split and rename them.\n",
    "    \n",
    "    Parameters:\n",
    "    directory_path (str): The path to the directory containing PDF files.\n",
    "    \"\"\"\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                split_and_rename_pdf(file_path)\n",
    "                print(f\"Processed file: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process file {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'path_to_pdf_file.pdf' with the actual path to the PDF file you want to split\n",
    "    # path_to_pdf_file = \"./testData/0115ExamAI_EV.pdf\"\n",
    "    # split_and_rename_pdf(path_to_pdf_file)\n",
    "    \n",
    "    directory_path = \"/Users/markgyao/Downloads/test01\"\n",
    "    process_directory(directory_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo deal with the situation where the ANS, PTS, REF, and NAT fields for each question might not all be on the same line, we can adjust our approach to ensure that our regex pattern is able to capture multiline data.\\n\\nAdjusting the Regular Expression\\nWe\\'ll use the re.DOTALL flag, which allows the . character in the regex pattern to match newline characters as well. This way, our regex pattern can capture fields that span multiple lines. Additionally, we\\'ll make sure our pattern is flexible enough to match varying amounts of whitespace and the possibility of fields appearing on separate lines.\\n\\nDetailed Pattern Explanation\\nHere\\'s the regex pattern and a detailed explanation of how it works:\\n\\npython\\nCopy code\\npattern = re.compile(r\\'(\\\\d+)\\\\s+ANS:\\\\s+(.*?)\\\\s+PTS:\\\\s+(\\\\d+)\\\\s+REF:\\\\s+(\\\\S+)\\\\s+NAT:\\\\s+([A-Z0-9.]+)\\', re.DOTALL)\\n(\\\\d+): Captures the question number, which consists of one or more digits.\\n\\\\s+: Matches one or more whitespace characters, including newlines.\\nANS:\\\\s+: Matches the literal string \"ANS:\" followed by one or more whitespace characters.\\n(.*?): Non-greedy match for any characters (including newlines, due to re.DOTALL), capturing the answer.\\n\\\\s+PTS:\\\\s+: Matches one or more whitespace characters, \"PTS:\", and one or more whitespace characters.\\n(\\\\d+): Captures the points, which consist of one or more digits.\\n\\\\s+REF:\\\\s+: Matches one or more whitespace characters, \"REF:\", and one or more whitespace characters.\\n(\\\\S+): Captures the reference, which consists of one or more non-whitespace characters.\\n\\\\s+NAT:\\\\s+: Matches one or more whitespace characters, \"NAT:\", and one or more whitespace characters.\\n([A-Z0-9.]+): Captures the national standard, which consists of uppercase letters, digits, or periods.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "import json\n",
    "import PyPDF2\n",
    "\n",
    "def parse_exam_answers0(pdf_path):\n",
    "    # Read the PDF content\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_path)\n",
    "    pdf_content = \"\"\n",
    "    \n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        pdf_content += page.extract_text() + \"\\n\"\n",
    "\n",
    "    # Parse the data\n",
    "    data = {}\n",
    "    pattern = re.compile(r'(\\d+)\\s+ANS:\\s*(.*?)\\s*PTS:\\s*(\\d+)\\s*REF:\\s*(\\w+)\\s*NAT:\\s*(\\S+)', re.DOTALL)\n",
    "\n",
    "    for match in pattern.finditer(pdf_content):\n",
    "        q_id = match.group(1)\n",
    "        ans = match.group(2).strip()\n",
    "        pts = match.group(3).strip()\n",
    "        ref = match.group(4).strip()\n",
    "        nat = match.group(5).strip()\n",
    "\n",
    "        data[q_id] = {\n",
    "            \"ANS\": ans,\n",
    "            \"PTS\": pts,\n",
    "            \"REF\": ref,\n",
    "            \"NAT\": nat\n",
    "        }\n",
    "\n",
    "    # Convert to JSON\n",
    "    json_data = json.dumps(data, indent=4)\n",
    "    \n",
    "    json_path = os.path.splitext(pdf_path)[0] + '_0.json'\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json_file.write(json_data)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Replace multiple spaces and line breaks with a single space\n",
    "    #text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def parse_exam_answers1(pdf_path):\n",
    "    # Read the PDF content\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_path)\n",
    "    pdf_content = \"\"\n",
    "    \n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        pdf_content += page.extract_text() + \"\\n\"\n",
    "    \n",
    "    # Normalize the extracted text\n",
    "    pdf_content = normalize_text(pdf_content)\n",
    "    \n",
    "    # Pattern to handle the structure\n",
    "    pattern = re.compile(r'(\\d+)\\s+ANS:\\s+(\\S.*?)\\s+PTS:\\s+(\\d+)\\s+REF:\\s+(\\S+)\\s+NAT:\\s+([A-Z0-9.]+)', re.DOTALL)\n",
    "    \n",
    "    data = {}\n",
    "    for match in pattern.finditer(pdf_content):\n",
    "        q_id = match.group(1)\n",
    "        ans = match.group(2).strip()\n",
    "        pts = match.group(3).strip()\n",
    "        ref = match.group(4).strip()\n",
    "        nat = match.group(5).strip()\n",
    "\n",
    "        data[q_id] = {\n",
    "            \"ANS\": ans,\n",
    "            \"PTS\": pts,\n",
    "            \"REF\": ref,\n",
    "            \"NAT\": nat\n",
    "        }\n",
    "\n",
    "    # Convert to JSON\n",
    "    json_data = json.dumps(data, indent=4,  ensure_ascii=False) ## note the difference from previous functions\n",
    "    \n",
    "    # Save JSON to file\n",
    "    json_path = os.path.splitext(pdf_path)[0] + '_1.json'\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json_file.write(json_data)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "r\"\"\"\n",
    "To deal with the situation where the ANS, PTS, REF, and NAT fields for each question might not all be on the same line, we can adjust our approach to ensure that our regex pattern is able to capture multiline data.\n",
    "\n",
    "Adjusting the Regular Expression\n",
    "We'll use the re.DOTALL flag, which allows the . character in the regex pattern to match newline characters as well. This way, our regex pattern can capture fields that span multiple lines. Additionally, we'll make sure our pattern is flexible enough to match varying amounts of whitespace and the possibility of fields appearing on separate lines.\n",
    "\n",
    "Detailed Pattern Explanation\n",
    "Here's the regex pattern and a detailed explanation of how it works:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "pattern = re.compile(r'(\\d+)\\s+ANS:\\s+(.*?)\\s+PTS:\\s+(\\d+)\\s+REF:\\s+(\\S+)\\s+NAT:\\s+([A-Z0-9.]+)', re.DOTALL)\n",
    "(\\d+): Captures the question number, which consists of one or more digits.\n",
    "\\s+: Matches one or more whitespace characters, including newlines.\n",
    "ANS:\\s+: Matches the literal string \"ANS:\" followed by one or more whitespace characters.\n",
    "(.*?): Non-greedy match for any characters (including newlines, due to re.DOTALL), capturing the answer.\n",
    "\\s+PTS:\\s+: Matches one or more whitespace characters, \"PTS:\", and one or more whitespace characters.\n",
    "(\\d+): Captures the points, which consist of one or more digits.\n",
    "\\s+REF:\\s+: Matches one or more whitespace characters, \"REF:\", and one or more whitespace characters.\n",
    "(\\S+): Captures the reference, which consists of one or more non-whitespace characters.\n",
    "\\s+NAT:\\s+: Matches one or more whitespace characters, \"NAT:\", and one or more whitespace characters.\n",
    "([A-Z0-9.]+): Captures the national standard, which consists of uppercase letters, digits, or periods.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_file_path = './testData/0115ExamAI_EV_answ.pdf'\n",
    "\n",
    "#answer_data = parse_exam_answers0(pdf_file_path)\n",
    "answer_data = parse_exam_answers1(pdf_file_path)\n",
    "#print(answer_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
